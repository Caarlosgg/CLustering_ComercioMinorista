#  Customer Intelligence & Segmentation: RFM + K-Means Clustering

![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![Seaborn](https://img.shields.io/badge/Seaborn-Data%20Viz-teal?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Completed-success?style=for-the-badge)

> **Transformando datos transaccionales en estrategias de retenci贸n.**
> Este proyecto implementa un modelo de Machine Learning no supervisado para segmentar clientes de un e-commerce mayorista, permitiendo identificar autom谩ticamente a los clientes VIP, detectar riesgos de abandono y optimizar campa帽as de marketing.

---

##  Tabla de Contenidos

1. [Contexto del Negocio](#-contexto-del-negocio)
2. [Sobre el Dataset](#-sobre-el-dataset)
3. [Metodolog铆a y Flujo de Trabajo](#-metodolog铆a-y-flujo-de-trabajo)
4. [Stack Tecnol贸gico](#-stack-tecnol贸gico)
5. [Resultados y Segmentaci贸n](#-resultados-y-segmentaci贸n)
6. [Visualizaci贸n Avanzada](#-visualizaci贸n-avanzada)
7. [C贸mo Ejecutar](#-c贸mo-ejecutar)
8. [Conclusiones](#-conclusiones)

---

##  Contexto del Negocio

En el sector retail, el costo de adquirir un nuevo cliente es **5 veces mayor** que retener a uno existente. Sin embargo, tratar a todos los clientes por igual es ineficiente.

El objetivo de este proyecto es aplicar la t茅cnica **RFM (Recency, Frequency, Monetary)** potenciada por algoritmos de Clustering para responder preguntas clave:
* 驴Qui茅nes son nuestros clientes m谩s valiosos (**VIP**)?
* 驴Qu茅 clientes est谩n en riesgo de abandonar la marca (**Churn Risk**)?
* 驴Qui茅nes tienen potencial para convertirse en grandes compradores?

---

##  Sobre el Dataset

Se utiliza el conjunto de datos p煤blico **[Online Retail Dataset](https://www.kaggle.com/datasets/hellbuoy/online-retail-customer-clustering)** del repositorio UCI Machine Learning.

* **Origen:** Transacciones de un e-commerce mayorista con sede en el Reino Unido.
* **Periodo:** 01/12/2010 a 09/12/2011.
* **Volumen Inicial:** 541,909 registros.
* **Variables Clave:** `InvoiceNo`, `StockCode`, `Quantity`, `InvoiceDate`, `UnitPrice`, `CustomerID`, `Country`.

**锔 Limpieza de Datos Realizada:**
* Eliminaci贸n de ~135,000 registros sin `CustomerID` (esenciales para el perfilado).
* Filtrado de transacciones con `Quantity <= 0` (Devoluciones) y `UnitPrice <= 0` (Errores/Regalos).
* **Dataset Final:** ~397,000 transacciones limpias.

---

## 锔 Metodolog铆a y Flujo de Trabajo

El proyecto sigue un pipeline riguroso de Data Science:

### 1. Ingenier铆a de Caracter铆sticas (RFM)
Transformamos los datos de nivel "transacci贸n" a nivel "cliente", calculando:
* **Recency (R):** D铆as transcurridos desde la 煤ltima compra hasta la fecha de corte.
* **Frequency (F):** N煤mero total de transacciones 煤nicas.
* **Monetary (M):** Suma total del valor de compra (`Quantity * UnitPrice`).

### 2. Preprocesamiento Estad铆stico
Los datos financieros reales presentan una fuerte asimetr铆a positiva (distribuci贸n Power Law). Para optimizar el rendimiento de K-Means:
* **Transformaci贸n Logar铆tmica:** Aplicada a R, F y M para "comprimir" los outliers y suavizar la distribuci贸n.
* **Escalado (StandardScaler):** Normalizaci贸n de datos (Media=0, Desviaci贸n=1) para que la variable "Monetary" (miles de $) no domine a "Frequency" (unidades) en el c谩lculo de distancias euclidianas.

### 3. Modelado (K-Means Clustering)
* **Determinaci贸n de K:** Se utilizaron el **M茅todo del Codo (Elbow Method)** y el **Coeficiente de Silueta** para determinar que **K=3** es el n煤mero 贸ptimo de segmentos.
* **Asignaci贸n Din谩mica de Nombres:** Se implement贸 un algoritmo l贸gico post-entrenamiento que asigna etiquetas de negocio (*VIP, Riesgo, Potenciales*) bas谩ndose en los centroides, evitando la asignaci贸n aleatoria de n煤meros (Cluster 0, 1, 2).

---

##  Stack Tecnol贸gico

* **Python 3.8+**
* **Pandas & NumPy:** Manipulaci贸n de datos y 谩lgebra lineal.
* **Scikit-Learn:**
    * `KMeans`: Algoritmo de clustering.
    * `StandardScaler`: Normalizaci贸n Z-Score.
    * `silhouette_score`: M茅trica de evaluaci贸n.
* **Visualizaci贸n:**
    * `Matplotlib` & `Seaborn`: Gr谩ficos est谩ticos y estad铆sticos.
    * `mpl_toolkits.mplot3d`: Visualizaci贸n espacial tridimensional.

---

##  Resultados y Segmentaci贸n

El modelo identific贸 exitosamente 3 perfiles de comportamiento distintos:

| Segmento | Descripci贸n del Perfil | Estrategia Recomendada |
| :--- | :--- | :--- |
| ** VIP / Top** | **Gasto Alto, Frecuencia Alta, Recencia Baja.** Son la columna vertebral del negocio. | Programas de fidelizaci贸n exclusivos, acceso anticipado, trato personalizado. |
| ** Potenciales** | **Gasto Medio, Frecuencia Media.** Clientes activos con margen de crecimiento. | Estrategias de *Up-selling* y *Cross-selling* para aumentar su ticket medio. |
| ** Riesgo / Perdidos** | **Recencia Muy Alta.** Hace mucho tiempo que no compran. | Campa帽as agresivas de reactivaci贸n (*Win-back*) o encuestas de satisfacci贸n. |

---

##  Visualizaci贸n Avanzada

El notebook genera un set completo de visualizaciones estrat茅gicas:

1.  **Dashboard de Distribuci贸n:** Gr谩ficos de Pastel y Barras para entender el tama帽o y valor monetario de cada grupo (Principio de Pareto).
2.  **Boxplots con Escala Logar铆tmica:** Para visualizar la dispersi贸n de la Recencia y el Gasto sin que los valores extremos distorsionen la imagen.
3.  **Mapas de Dispersi贸n (2D):** Visualizaci贸n de fronteras entre grupos (ej. *Frequency vs Monetary*).
4.  **Snake Plot:** Gr谩fico t茅cnico estandarizado que muestra la desviaci贸n de cada atributo respecto a la media global.
5.  **Mapa de Calor (Heatmap):** Tabla de importancia relativa porcentual.

*(Nota: Ejecuta el notebook para generar las im谩genes interactivas y est谩ticas)*

---

##  C贸mo Ejecutar

1.  Clona el repositorio:
    ```bash
    git clone [https://github.com/tu-usuario/customer-clustering-rfm.git](https://github.com/tu-usuario/customer-clustering-rfm.git)
    ```
2.  Instala las dependencias necesarias:
    ```bash
    pip install pandas numpy matplotlib seaborn scikit-learn
    ```
3.  Abre el archivo `Clustering.ipynb` en Jupyter Notebook, VS Code o Google Colab.
4.  Aseg煤rate de tener el archivo `OnlineRetail.csv` en el mismo directorio.
5.  Ejecuta todas las celdas para reproducir el an谩lisis.

---

##  Conclusiones

Este proyecto demuestra c贸mo la ciencia de datos puede transformar una base de datos bruta en **decisiones de negocio**. Hemos logrado separar matem谩ticamente a los clientes leales de los que est谩n en riesgo, proporcionando al equipo de marketing una herramienta precisa para optimizar su presupuesto y mejorar la retenci贸n de clientes.
